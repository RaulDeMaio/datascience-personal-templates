Hereâ€™s the updated `README.md` tailored for your **uv-based Data Science Project Template**, replacing all Conda references with `uv`, and fully aligned with the updated project structure, CLI, and GitHub Actions CI.

---

# ğŸ§  Data Science Project Template (uv version)

This template is designed for fast, reproducible, and maintainable personal data science projects using [`uv`](https://github.com/astral-sh/uv) for dependency management.

Inspired by [khuyetran1401's article](https://towardsdatascience.com/how-to-structure-an-ml-project-for-reproducibility-and-maintainability-54d5e53b4c82?sk=c3d05ae5b8ccc95822618d0dacfad8a4), this setup is intended to stay lightweight and clean, while still enforcing quality practices.

> For production-grade orchestration, consider [Kedro](https://docs.kedro.org/en/stable/).

---

## ğŸš€ Features

- Build project structure instantly with Cookiecutter
- Manage environments and dependencies with [`uv`](https://github.com/astral-sh/uv)
- Pre-commit checks for formatting, linting, typing, notebook quality
- Auto-generate docs using `pdoc`
- Run unit tests via `pytest`
- Logging setup for both scripts and notebooks
- Built-in CLI for full automation

---

## ğŸ§° Tools Used

| Tool           | Purpose                                                |
|----------------|--------------------------------------------------------|
| [uv](https://github.com/astral-sh/uv) | Fast dependency management & venv |
| [pre-commit](https://pre-commit.com/) | Code quality automation |
| [pytest](https://docs.pytest.org/) | Unit testing framework |
| [mypy](http://mypy-lang.org/) | Static type checking |
| [black](https://black.readthedocs.io/en/stable/) | Code formatting |
| [flake8](http://flake8.pycqa.org/) | Linting |
| [nbQA](https://nbqa.readthedocs.io/) | Notebook linting |
| [pdoc](https://pdoc.dev/) | Documentation generator |
| [click](https://click.palletsprojects.com/) | CLI interface for setup |

---

## ğŸ§± Template Structure

```bash
.
â”œâ”€â”€ config/                    # Optional config files
â”œâ”€â”€ data/                      # Data folders (not tracked)
â”‚   â”œâ”€â”€ 01_raw/                # Raw immutable data
â”‚   â”œâ”€â”€ 02_primary/            # Domain-level cleaned data
â”‚   â”œâ”€â”€ 03_feature/            # Features for modeling
â”‚   â”œâ”€â”€ 04_model_input/
â”‚   â”œâ”€â”€ 05_model_output/
â”‚   â””â”€â”€ 06_reporting/
â”œâ”€â”€ docs/                      # Auto-generated documentation
â”œâ”€â”€ models/                    # Saved models
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ 00_example_notebook.ipynb
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ scripts/                   # CLI and utility scripts
â”‚   â””â”€â”€ setup_cli.py
â”œâ”€â”€ src/                       # Core source code
â”‚   â”œâ”€â”€ logging_utils.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â””â”€â”€ test_main.py
â”œâ”€â”€ .github/workflows/ci.yml  # GitHub Actions CI workflow
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ Makefile
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

---

## âš™ï¸ Quick Start

### ğŸ§± 1. Generate a Project

```bash
pip install cookiecutter
cookiecutter https://github.com/radema/datascience-personal-templates
```

### ğŸ›  2. Setup the Project with uv

```bash
uv venv
uv pip install -e .
make setup  # runs pre-commit install
```

Or use the full automation CLI:

```bash
python scripts/setup_cli.py all
```

---

## ğŸ”§ Developer CLI

You can automate common steps using:

```bash
python scripts/setup_cli.py create-env
python scripts/setup_cli.py install
python scripts/setup_cli.py test
python scripts/setup_cli.py docs
```

---

## ğŸ§ª Testing

Run tests:

```bash
make test
```

Or from the CLI:

```bash
python scripts/setup_cli.py test
```

---

## ğŸ““ Notebooks

Located in `notebooks/`, using a numbered convention:

```
01_data_exploration.ipynb
02_feature_engineering.ipynb
03_model_training.ipynb
```

Best practices:
- Keep modular and clean
- Restart + clear outputs before commits
- Auto-checked with `nbQA` in pre-commit

---

## ğŸ§¼ Pre-commit Hooks

Includes:
- `black`, `flake8`, `isort`, `mypy`, `interrogate`
- `nbQA` for notebook linting
- Whitespace, large file checks

Run manually with:

```bash
pre-commit run --all-files
```

---

## ğŸ“š Generate Docs

Use:

```bash
make docs
```
Docs will be saved to the `docs/` folder using [`pdoc`](https://pdoc.dev).

---

## ğŸ” Continuous Integration

This project includes GitHub Actions CI:
- Installs environment with `uv`
- Runs pre-commit hooks
- Runs `pytest`

You can find the config under `.github/workflows/ci.yml`.

---

## ğŸ“– References

- [khuyentran1401/data-science-template](https://github.com/khuyentran1401/data-science-template/blob/dvc-poetry/README.md)
- [Kedro starters](https://github.com/kedro-org/kedro-starters)
- [uv documentation](https://github.com/astral-sh/uv)

---
=======
Let me know if you want me to write the updated `Makefile`, `.pre-commit-config.yaml`, or help generate badges and shields for the top of the README!